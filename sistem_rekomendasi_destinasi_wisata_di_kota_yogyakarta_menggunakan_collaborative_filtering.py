# -*- coding: utf-8 -*-
"""SISTEM REKOMENDASI DESTINASI WISATA DI KOTA YOGYAKARTA MENGGUNAKAN COLLABORATIVE FILTERING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CDvgynhbFcaiFja9h17eePXD1W-YsL-8

# SISTEM REKOMENDASI DESTINASI WISATA DI KOTA YOGYAKARTA MENGGUNAKAN COLLABORATIVE FILTERING

## Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from zipfile import ZipFile

import seaborn as sns
import matplotlib.pyplot as plt

# %matplotlib inline
sns.set(palette = 'Set1')

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

import warnings
warnings.filterwarnings('ignore')

import os

"""## Data Collecting"""

! kaggle datasets download -d aprabowo/indonesia-tourism-destination

with ZipFile("indonesia-tourism-destination.zip", 'r') as zip:
    zip.extractall("indonesia-tourism-destination")

for dirname, _, filenames in os.walk('indonesia-tourism-destination'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

"""## Data Understanding"""

# Inisialisasi variabel untuk menyimpan dataset
rating = pd.read_csv('/content/indonesia-tourism-destination/tourism_rating.csv')
place = pd.read_csv('/content/indonesia-tourism-destination/tourism_with_id.csv')
user =  pd.read_csv('/content/indonesia-tourism-destination/user.csv')

from google.colab import drive
drive.mount('/content/drive')

"""### Place Data"""

place.head()

place.info()

# Check city the names of cities in the City variable
unique_cities = place['City'].unique()
print("City name:", unique_cities)

"""#### Rating Data"""

rating.head()

rating.info()

"""#### User Data"""

user.head()

user.info()

"""### Exploratory Data Analysis"""

# Membuat data frame yang memuat wisata dengan frekuensi rating terbanyak
top_10 = rating['Place_Id'].value_counts().reset_index()[0:10]
top_10.columns = ['Place_Id', 'count']
top_10 = pd.merge(top_10, place[['Place_Id', 'Place_Name', 'City']], how='left', on='Place_Id')

# Visualisasi wisata dengan frekuensi rating terbanyak
plt.figure(figsize=(8, 5))
sns.barplot(x='count', y='Place_Name', data=top_10)
plt.title('Jumlah Tempat Wisata dengan Freukensi Rating Terbanyak', pad=20)
plt.ylabel('Nama Lokasi')
plt.xlabel('Jumlah Rating')
plt.show()

top_10_with_city = top_10[['Place_Name', 'City']]
print(top_10_with_city)

# Visualisasi jumlah kategori wisata di Kota Yogyakarta
sns.countplot(y='Category', data=place[place['City'] == 'Yogyakarta'])
plt.title('Perbadingan Jumlah Kategori Wisata di Kota Yogyakarta', pad=20)
plt.show()

# Visualisasi distribusi dari usia user
plt.figure(figsize=(5, 3))
sns.boxplot(user['Age'])
plt.title('Distribusi Usia User', pad=20)
plt.show()

# Visualisasi distribusi harga masuk wisata di kota Yogyakarta
plt.figure(figsize=(11, 5))
sns.boxplot(x='Category', y='Price', data=place)
plt.title('Distribusi Harga Masuk Wisata di Kota Yogyakarta', pad=20)
plt.show()

# Memfilter asal kota dari user
asal = user['Location'].apply(lambda x : x.split(',')[0])

# Visualisasi asal kota dari user
plt.figure(figsize=(8, 6))
sns.countplot(y=asal)
plt.title('Jumlah Asal Kota dari User')
plt.show()

"""## Data Preparation"""

place.head()

# Menghapus kolom yang tidak digunakan
place = place.drop(['Unnamed: 11',	'Unnamed: 12', 'Time_Minutes'], axis=1)
place.head()

# Hanya menggunakan data wisata pada kota Yogyakarta
place = place[place['City']=='Yogyakarta']
place.head()

# Mengubah rating agar hanya berisi rating pada kota Yogyakarta
# Gabungkan 2 data frame yaitu rating dan place berdasarkan kolom 'Place_Id'
rating = pd.merge(rating, place[['Place_Id']], how='right', on='Place_Id')
rating.head()

# Mengubah rating agar hanya berisi wisatawan pada kota Yogyakarta
# Gabungkan 2 data frame yaitu user dan rating berdasarkan kolom 'User_Id', serta menghapus dupilkat
user = pd.merge(user, rating[['User_Id']], how='right', on='User_Id')
user.drop_duplicates().sort_values('User_Id')
user.head()

"""### Encoding"""

# Membaca dataset untuk dilakukan encoding
df = rating.copy()
df.head()

# Membuat fungsi untuk encoding
def dict_encoder(col, data=df):
  unique_val = data[col].unique().tolist()

  val_to_val_encoded = { x: i for i, x in enumerate(unique_val)}

  val_encoded_to_val = {i: x for i, x in enumerate(unique_val)}
  return val_to_val_encoded, val_encoded_to_val

# Encoding and Mapping pada kolom user
user_to_user_encoded, user_encoded_to_user = dict_encoder('User_Id')

df['user'] = df['User_Id'].map(user_to_user_encoded)

print('Mapping dari User_Id ke nilai terenkripsi')
print(user_to_user_encoded)
print('/nMapping dari nilai terenkripsi keembali User_Id')
print(user_encoded_to_user)
print('/nDataframe setelah encoding')
print(pd.DataFrame(df))

# Encoding and Mapping pada kolom place
place_to_place_encoded, place_encoded_to_place = dict_encoder('Place_Id')

df['place'] = df['Place_Id'].map(place_to_place_encoded)

print('Mapping dari Place_Id ke nilai terenkripsi')
print(place_to_place_encoded)
print('/nMapping dari nilai terenkripsi keembali Place_Id')
print(place_encoded_to_place)
print('/nDataframe setelah encoding')
print(pd.DataFrame(df))

"""### See on Overview of the Data Modelling"""

num_users, num_place = len(user_to_user_encoded), len(place_to_place_encoded)

df['Place_Ratings'] = df['Place_Ratings'].values.astype(np.float32)

min_rating, max_rating = min(df['Place_Ratings']), max(df['Place_Ratings'])

print(f'Number of User: {num_users}, Number of Place: {num_place}, Min Rating: {min_rating}, Max Rating:')

# Mengecek dataset
df = df.sample(frac=1, random_state=42)
df.head()

"""## Modeling Machine Learning using RecommenderNet

### Split Data into Train and Test Data
"""

# Inisialisasi var x untuk mencocokkan data user dan place menjadi 1 value
x = df[['user', 'place']].values

# Inisialisasi var y untuk membuat rating dari hasil
y = df['Place_Ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data test
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

"""### Function Initialization"""

class RecommenderNet(tf.keras.Model):

  # Inisialisasi fungsi
  def __init__(self, num_users, num_places, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_places = num_places
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.places_embedding = layers.Embedding(
        num_places,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.places_bias = layers.Embedding(num_places, 1)

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:,0])
    places_vector = self.places_embedding(inputs[:,1])
    places_bias = self.places_bias(inputs[:,1])

    dot_user_places = tf.tensordot(user_vector, places_vector, 2)

    x = dot_user_places + user_bias + places_bias

    return tf.nn.sigmoid(x)

"""### Model Initialization"""

model = RecommenderNet(num_users, num_place, 50)

model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.0004),
    metrics = [tf.keras.metrics.RootMeanSquaredError()]
)

"""### Callbacks Initialization"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_root_mean_squared_error')<0.25):
      print('Lapor! Metriks validasi sudah sesuai harapan')
      self.model.stop_training = True

"""### Training Model"""

history = model.fit(
    x = x_train,
    y = y_train,
    epochs = 100,
    validation_data = (x_val, y_val),
    callbacks = [myCallback()]
)

# Menampilkan plot loss dan validation
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.ylim(ymin=0, ymax=0.4)
plt.legend(['train', 'test'], loc='center left')
plt.show()

"""## Predict Top 7 Recommendation"""

# Menyiapkan dataframe
place_df = place[['Place_Id', 'Place_Name', 'Category', 'Rating', 'Price']]
place_df.columns = ['id', 'place_name', 'category', 'rating', 'price']
df = rating.copy()

# Menamgbil sample user
user_id = df.User_Id.sample(1).iloc[0]
place_visited_by_user = df[df.User_Id == user_id]

# Membuat data lokasi yang belum dikunjungi user
place_not_visited = place_df[~place_df['id'].isin(place_visited_by_user.Place_Id.values)]['id']
place_not_visited = list(
    set(place_not_visited)
    .intersection(set(place_to_place_encoded.keys()))
)
place_not_visited = [[place_to_place_encoded.get(x)] for x in place_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_place_array = np.hstack(
    ([[user_encoder]] * len(place_not_visited), place_not_visited)
)

# Mengambil top 7 rekomendasi
ratings = model.predict(user_place_array).flatten()
top_ratings_indices = ratings.argsort()[-7:][::-1]
recommended_place_ids = [
    place_encoded_to_place.get(place_not_visited[x][0]) for x in top_ratings_indices
]

print('Daftar rekomendasi destinasi wisata di Kota Yogyakarta untuk: {}'.format('User' + str(user_id)))
print('===' * 15, '\n')
print('----' * 15)
print('Tempat dengan rating wisata paling tinggi dari user')
print('----' * 15)

top_place_user = (
    place_visited_by_user.sort_values(
        by = 'Place_Ratings',
        ascending=False
    )
    .head()
    .Place_Id.values
)

place_df_rows = place_df[place_df['id'].isin(top_place_user)]
for row in place_df_rows.itertuples():
  print(row.place_name, ':', row.category)

print('')
print('----' * 15)
print('Top 7 place recommendation')
print('----' * 15)

recommended_place = place_df[place_df['id'].isin(recommended_place_ids)]
for i, row in recommended_place.iterrows():
  print(i, '-', row.place_name, '\n', row.category, ',', 'Harga Tiket Masuk', row.price, ',', 'Rating Wisata', row.rating, '\n')

print('---' *15)

